{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import skew\n",
    "from scipy import stats\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.stats import norm\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv.zip', compression='zip')\n",
    "test = pd.read_csv('Test.csv.zip', compression='zip')\n",
    "# train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'Id' column\n",
    "train_ID = train['id']\n",
    "test_ID = test['id']\n",
    "\n",
    "# Now drop the 'Id' column since it's unnecessary for the prediction process.\n",
    "train.drop(\"id\", axis = 1, inplace = True)\n",
    "test.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is : (100000, 24)\n",
      "Test data size is : (100000, 23)\n",
      "Combined dataset size is : (200000, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axreldable/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Combining Datasets\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.price.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['price'], axis=1, inplace=True)\n",
    "print(\"Train data size is : {}\".format(train.shape))\n",
    "print(\"Test data size is : {}\".format(test.shape))\n",
    "print(\"Combined dataset size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка параметров\n",
    "all_data[['build_tech']] = all_data[['build_tech']].replace(np.nan, 0.5)\n",
    "all_data[['metro_dist']] = all_data[['metro_dist']].replace(np.nan, 15.0)\n",
    "all_data[['g_lift']] = all_data[['g_lift']].replace(np.nan, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 58)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.drop(\"date\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw1\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw2\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw3\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw4\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw5\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw6\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw7\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw8\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw9\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw10\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw11\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw12\", axis = 1, inplace = True)\n",
    "# all_data.drop(\"kw13\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any missing values left\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 58 columns):\n",
      "area               200000 non-null int64\n",
      "balcon             200000 non-null int64\n",
      "build_tech         200000 non-null float64\n",
      "floor              200000 non-null int64\n",
      "g_lift             200000 non-null float64\n",
      "kw1                200000 non-null int64\n",
      "kw10               200000 non-null int64\n",
      "kw11               200000 non-null int64\n",
      "kw12               200000 non-null int64\n",
      "kw13               200000 non-null int64\n",
      "kw2                200000 non-null int64\n",
      "kw3                200000 non-null int64\n",
      "kw4                200000 non-null int64\n",
      "kw5                200000 non-null int64\n",
      "kw6                200000 non-null int64\n",
      "kw7                200000 non-null int64\n",
      "kw8                200000 non-null int64\n",
      "kw9                200000 non-null int64\n",
      "metro_dist         200000 non-null float64\n",
      "n_photos           200000 non-null int64\n",
      "rooms              200000 non-null int64\n",
      "street_id          200000 non-null int64\n",
      "date_2011-01-01    200000 non-null uint8\n",
      "date_2011-02-01    200000 non-null uint8\n",
      "date_2011-03-01    200000 non-null uint8\n",
      "date_2011-04-01    200000 non-null uint8\n",
      "date_2011-05-01    200000 non-null uint8\n",
      "date_2011-06-01    200000 non-null uint8\n",
      "date_2011-07-01    200000 non-null uint8\n",
      "date_2011-08-01    200000 non-null uint8\n",
      "date_2011-09-01    200000 non-null uint8\n",
      "date_2011-10-01    200000 non-null uint8\n",
      "date_2011-11-01    200000 non-null uint8\n",
      "date_2011-12-01    200000 non-null uint8\n",
      "date_2012-01-01    200000 non-null uint8\n",
      "date_2012-02-01    200000 non-null uint8\n",
      "date_2012-03-01    200000 non-null uint8\n",
      "date_2012-04-01    200000 non-null uint8\n",
      "date_2012-05-01    200000 non-null uint8\n",
      "date_2012-06-01    200000 non-null uint8\n",
      "date_2012-07-01    200000 non-null uint8\n",
      "date_2012-08-01    200000 non-null uint8\n",
      "date_2012-09-01    200000 non-null uint8\n",
      "date_2012-10-01    200000 non-null uint8\n",
      "date_2012-11-01    200000 non-null uint8\n",
      "date_2012-12-01    200000 non-null uint8\n",
      "date_2013-01-01    200000 non-null uint8\n",
      "date_2013-02-01    200000 non-null uint8\n",
      "date_2013-03-01    200000 non-null uint8\n",
      "date_2013-04-01    200000 non-null uint8\n",
      "date_2013-05-01    200000 non-null uint8\n",
      "date_2013-06-01    200000 non-null uint8\n",
      "date_2013-07-01    200000 non-null uint8\n",
      "date_2013-08-01    200000 non-null uint8\n",
      "date_2013-09-01    200000 non-null uint8\n",
      "date_2013-10-01    200000 non-null uint8\n",
      "date_2013-11-01    200000 non-null uint8\n",
      "date_2013-12-01    200000 non-null uint8\n",
      "dtypes: float64(3), int64(19), uint8(36)\n",
      "memory usage: 40.4 MB\n"
     ]
    }
   ],
   "source": [
    "all_data\n",
    "all_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xt, y, yt = sklearn.model_selection.train_test_split(train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with k-folds\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= -cross_val_score(model, train.values, y_train, scoring=\"neg_mean_absolute_error\", cv = kf)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1)) # 1692737.2141\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.001, random_state=1)) # 1692737.2140\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha = 0.1, random_state=1)) # 1692737.2017\n",
    "\n",
    "# date include\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha=5, normalize=False, max_iter=1000, warm_start=False, random_state=1)) # 1692972.0131\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha=5, normalize=False, max_iter=500, warm_start=False, random_state=1)) # 1693997.8751\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha=5, normalize=False, max_iter=5000, warm_start=False, random_state=1)) # 1692268.2914\n",
    "\n",
    "# all priznaki\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=5, normalize=False, max_iter=5000, warm_start=False, random_state=1)) # 1692268.2914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 1691357.5555 (26581.8762)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Lasso(alpha=5, normalize=False, max_iter=5000, warm_start=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=5, copy_X=True, fit_intercept=True, max_iter=5000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=1,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01553279e+05,  4.29368121e+05,  5.22254990e+05,  5.76082417e+04,\n",
       "       -3.05961099e+03,  2.31807418e+05,  6.02964060e+05,  1.55009807e+06,\n",
       "       -4.31860431e+05,  2.72455334e+05, -9.24753915e+04, -2.72117244e+05,\n",
       "       -2.74598654e+05,  5.13248739e+04,  3.53140353e+05,  8.41057171e+05,\n",
       "       -1.09129457e+05,  3.67426076e+04, -5.34125021e+04,  2.24759818e+05,\n",
       "       -1.80133222e+06, -8.48817287e+02, -1.04790936e+05, -1.68292509e+05,\n",
       "       -9.66363763e+04, -7.62892559e+04, -5.77824004e+04,  0.00000000e+00,\n",
       "       -3.94684284e+04, -8.98548228e+03,  7.14783786e+04,  9.50589189e+04,\n",
       "        1.24988472e+04,  2.32689923e+05,  3.15936227e+04,  1.21546616e+05,\n",
       "       -2.50443245e+04,  9.33709282e+04, -3.31117287e+04,  7.42986888e+04,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgb.fit(X, y)\n",
    "\n",
    "# pred = model_xgb.predict(Xt)\n",
    "\n",
    "# score = sklearn.metrics.mean_absolute_error(yt, pred)\n",
    "\n",
    "# print('XGBRegressor max_depth=13 n_estimators=10000: %s' % (score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
